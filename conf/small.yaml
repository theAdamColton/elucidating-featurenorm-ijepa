conf:
  mode: train

  should_compile: true
  dtype: bfloat16
  device: cuda

  steady_lr: 1e-3
  num_lr_cooldown_steps: 100000
  end_lr: 7e-5

  batch_size: 320
  num_workers: 4

  num_register_tokens: 0
  validate_every_num_epochs: 50

  model:

    encoder:
      input_size: 768
      num_transformer_blocks: 12
      block_config:
        mlp_config:
          embed_dim: 384
          num_experts: 16
          norm_mode: layernorm
        attention_config:
          embed_dim: 384
          head_dim: 64
          num_attention_heads: 6
          should_use_qk_norm: true
        norm_mode: layernorm
      norm_out_mode: dyntanh
      norm_elementwise_affine: true

    predictor:
      input_size: 384
      num_transformer_blocks: 4
      block_config:
        mlp_config:
          embed_dim: 256
          num_experts: 8
          norm_mode: layernorm
        attention_config:
          embed_dim: 256
          head_dim: 64
          num_attention_heads: 4
          should_use_qk_norm: true
        norm_mode: layernorm
      norm_out_mode: layernorm

    predictor_batch_repeat: 4
    target_norm_mode: disabled
    should_predict_from_all_target: false
    should_attempt_mask_dropping: true
    predictor_context_capacity: 0.25
    predictor_target_capacity: 0.25

    sample_predictor_context_with_replacement: true
    sample_predictor_targets_with_replacement: true

  context_target_dataset:
    min_context_capacity: 0.25
    max_context_capacity: 0.5
    absolute_max_context_capacity: 0.5
    mask_window_size: 2
