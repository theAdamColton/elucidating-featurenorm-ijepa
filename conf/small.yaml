conf:
  mode: train

  should_compile: true
  dtype: bfloat16
  device: cuda

  batch_size: 256
  num_workers: 4

  ema_beta_start: 0.8
  ema_beta: 0.996
  ema_beta_warmup_steps: 1000

  start_lr: 1e-4
  lr: 5e-4
  num_warmup_steps: 10000

  interp_warmup_steps: 30000

  num_register_tokens: 0
  validate_every_num_epochs: 40

  model:

    encoder:
      input_size: 768
      num_transformer_blocks: 12
      block_config:
        mlp_config:
          embed_dim: 384
          num_experts: 8
          norm_mode: layernorm
        attention_config:
          embed_dim: 384
          head_dim: 64
          num_attention_heads: 6
          should_use_qk_norm: true
        norm_mode: layernorm
      norm_out_mode: dyntanh
      norm_elementwise_affine: false

    predictor:
      input_size: 384
      num_transformer_blocks: 6
      block_config:
        mlp_config:
          embed_dim: 256
          num_experts: 8
          norm_mode: layernorm
        attention_config:
          embed_dim: 256
          head_dim: 64
          num_attention_heads: 4
          should_use_qk_norm: true
        norm_mode: layernorm
      norm_out_mode: dyntanh

    predictor_batch_repeat: 4
    target_norm_mode: disabled
    should_predict_from_all_target: false
    should_attempt_mask_dropping: true
    predictor_context_capacity: 0.25
    predictor_target_capacity: 0.25

  context_target_dataset:
    min_context_capacity: 0.25
    max_context_capacity: 0.5
    absolute_max_context_capacity: 0.5
